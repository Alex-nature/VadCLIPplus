#!/usr/bin/env python3
"""
ä½¿ç”¨CLIPæ–‡æœ¬ç¼–ç å™¨è®¡ç®—ç›¸ä¼¼åº¦ï¼Œå¯¹ç”Ÿæˆçš„çŸ­è¯­è¿›è¡Œè¿‡æ»¤å’Œæ’åº
"""

import os
import json
import torch
import numpy as np
from pathlib import Path
import argparse
from typing import Dict, List, Tuple

# å¯¼å…¥CLIPç›¸å…³æ¨¡å—
import sys
sys.path.append('src')
from clip import clip


class PhraseSimilarityFilter:
    """
    ä½¿ç”¨CLIPè®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ï¼Œå¯¹çŸ­è¯­è¿›è¡Œè¿‡æ»¤å’Œæ’åº
    """

    def __init__(self, model_name: str = "ViT-B/16", device: str = "cuda" if torch.cuda.is_available() else "cpu"):
        """
        åˆå§‹åŒ–ç›¸ä¼¼åº¦è¿‡æ»¤å™¨

        Args:
            model_name: CLIPæ¨¡å‹åç§°
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device
        self.model_name = model_name

        print(f"Loading CLIP model: {model_name} on {device}")
        self.model, self.preprocess = clip.load(model_name, device=device)

        # å†»ç»“æ¨¡å‹å‚æ•°
        for param in self.model.parameters():
            param.requires_grad = False

        self.model.eval()
        print("âœ“ CLIP model loaded and frozen")

    def encode_texts(self, texts: List[str]) -> torch.Tensor:
        """
        ä½¿ç”¨CLIPç¼–ç æ–‡æœ¬åˆ—è¡¨

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨

        Returns:
            æ–‡æœ¬åµŒå…¥å¼ é‡ (N, D)ï¼Œæ•°æ®ç±»å‹ä¸ºfloat32
        """
        # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜æº¢å‡º
        batch_size = 32
        all_embeddings = []

        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]

            # CLIP tokenize
            text_tokens = clip.tokenize(batch_texts).to(self.device)

            # ç¼–ç æ–‡æœ¬
            with torch.no_grad():
                text_features = self.model.encode_text(text_tokens)
                # ç¡®ä¿è½¬æ¢ä¸ºfloat32ç±»å‹
                text_features = text_features.float()
                # L2å½’ä¸€åŒ–
                text_features = text_features / text_features.norm(dim=-1, keepdim=True)

            all_embeddings.append(text_features.cpu())

        # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡ï¼Œå¹¶ç¡®ä¿è¿”å›float32ç±»å‹
        result = torch.cat(all_embeddings, dim=0)
        return result.float()

    def calculate_similarities(self, category_embedding: torch.Tensor,
                             phrase_embeddings: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—ç±»åˆ«åµŒå…¥ä¸çŸ­è¯­åµŒå…¥ä¹‹é—´çš„ç›¸ä¼¼åº¦

        Args:
            category_embedding: ç±»åˆ«åµŒå…¥ (1, D)
            phrase_embeddings: çŸ­è¯­åµŒå…¥ (N, D)

        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (N,)
        """
        # ç¡®ä¿ä¸¤ä¸ªå¼ é‡éƒ½æ˜¯float32ç±»å‹
        category_embedding = category_embedding.float()
        phrase_embeddings = phrase_embeddings.float()

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = torch.matmul(phrase_embeddings, category_embedding.T).squeeze(-1)
        return similarities

    def select_topk_phrases(self, category: str, phrases: List[str],
                          top_k: int = 5) -> Tuple[List[str], List[float]]:
        """
        ä¸ºæŒ‡å®šç±»åˆ«é€‰æ‹©top-kæœ€ç›¸ä¼¼çš„çŸ­è¯­

        Args:
            category: ç±»åˆ«åç§°
            phrases: è¯¥ç±»åˆ«çš„æ‰€æœ‰çŸ­è¯­
            top_k: é€‰æ‹©çš„æ•°é‡

        Returns:
            (é€‰ä¸­çš„çŸ­è¯­åˆ—è¡¨, å¯¹åº”çš„ç›¸ä¼¼åº¦åˆ†æ•°åˆ—è¡¨)
        """
        if not phrases:
            return [], []

        # ç¼–ç ç±»åˆ«å’ŒçŸ­è¯­
        all_texts = [category] + phrases
        embeddings = self.encode_texts(all_texts)

        # åˆ†ç¦»ç±»åˆ«å’ŒçŸ­è¯­åµŒå…¥
        category_embedding = embeddings[0:1]  # (1, D)
        phrase_embeddings = embeddings[1:]    # (N, D)

        # ç¡®ä¿ä¸¤ä¸ªå¼ é‡éƒ½åœ¨åŒä¸€è®¾å¤‡ä¸Šä¸”ç±»å‹ç›¸åŒ
        if category_embedding.device != phrase_embeddings.device:
            category_embedding = category_embedding.to(phrase_embeddings.device)

        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = self.calculate_similarities(category_embedding, phrase_embeddings)

        # é€‰æ‹©top-k
        top_k = min(top_k, len(similarities))
        top_values, top_indices = torch.topk(similarities, top_k)

        # è·å–å¯¹åº”çš„çŸ­è¯­å’Œç›¸ä¼¼åº¦
        selected_phrases = [phrases[idx] for idx in top_indices.tolist()]
        selected_similarities = top_values.tolist()

        return selected_phrases, selected_similarities

    def filter_all_categories(self, input_file: str = "enhanced_prompts.json",
                            output_file: str = "filtered_prompts.json",
                            top_k: int = 5) -> Dict[str, Dict]:
        """
        è¿‡æ»¤æ‰€æœ‰ç±»åˆ«çš„çŸ­è¯­ï¼Œé€‰æ‹©top-kæœ€ç›¸ä¼¼çš„

        Args:
            input_file: è¾“å…¥JSONæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„
            top_k: æ¯ä¸ªç±»åˆ«ä¿ç•™çš„çŸ­è¯­æ•°é‡

        Returns:
            è¿‡æ»¤åçš„ç»“æœå­—å…¸
        """
        print(f"Loading phrases from {input_file}...")

        # è¯»å–è¾“å…¥æ–‡ä»¶
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        categories = data.get('categories', {})
        print(f"Found {len(categories)} categories to process")

        filtered_results = {}
        total_phrases_selected = 0

        # å¤„ç†æ¯ä¸ªç±»åˆ«
        for category, phrases in categories.items():
            print(f"\nProcessing category: '{category}' ({len(phrases)} phrases)")

            # é€‰æ‹©top-kçŸ­è¯­
            selected_phrases, similarities = self.select_topk_phrases(category, phrases, top_k)

            # ä¿å­˜ç»“æœ
            filtered_results[category] = {
                'phrases': selected_phrases,
                'similarities': similarities,
                'original_count': len(phrases),
                'selected_count': len(selected_phrases)
            }

            total_phrases_selected += len(selected_phrases)

            # æ˜¾ç¤ºç»“æœ
            print(f"  âœ“ Selected {len(selected_phrases)} top phrases:")
            for i, (phrase, sim) in enumerate(zip(selected_phrases, similarities), 1):
                print(f"    {i}. \"{phrase}\"")
                print(f"       Similarity: {sim:.4f}")

            # æ˜¾ç¤ºç›¸ä¼¼åº¦ç»Ÿè®¡
            sim_array = np.array(similarities)
            print(f"       Similarity stats - Min: {sim_array.min():.4f}, Max: {sim_array.max():.4f}, Avg: {sim_array.mean():.4f}")

        # æ„å»ºè¾“å‡ºæ•°æ®ç»“æ„
        output_data = {
            "metadata": {
                "description": "Filtered text prompts based on CLIP similarity",
                "source_file": input_file,
                "clip_model": self.model_name,
                "total_categories": len(filtered_results),
                "total_phrases_selected": total_phrases_selected,
                "top_k_per_category": top_k,
                "filter_method": "cosine_similarity"
            },
            "categories": filtered_results
        }

        # ä¿å­˜ç»“æœ
        print(f"\nSaving filtered results to {output_file}...")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)

        print("âœ“ Filtering completed!")
        print(f"  - Total categories: {len(filtered_results)}")
        print(f"  - Total phrases selected: {total_phrases_selected}")

        return output_data


def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(description="Filter phrases by CLIP similarity")
    parser.add_argument("--input", type=str, default="enhanced_prompts.json",
                       help="Input JSON file with phrases")
    parser.add_argument("--output", type=str, default="filtered_prompts.json",
                       help="Output JSON file for filtered results")
    parser.add_argument("--top-k", type=int, default=5,
                       help="Number of top phrases to select per category")
    parser.add_argument("--model", type=str, default="ViT-B/16",
                       help="CLIP model to use")
    parser.add_argument("--device", type=str, default=None,
                       help="Device to use (auto-detect if not specified)")

    args = parser.parse_args()

    # è®¾ç½®è®¾å¤‡
    if args.device is None:
        args.device = "cuda" if torch.cuda.is_available() else "cpu"

    print("=== CLIP Phrase Similarity Filter ===")
    print(f"Input file: {args.input}")
    print(f"Output file: {args.output}")
    print(f"Top-k per category: {args.top_k}")
    print(f"CLIP model: {args.model}")
    print(f"Device: {args.device}")
    print()

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input):
        print(f"âŒ Input file not found: {args.input}")
        return

    # åˆå§‹åŒ–è¿‡æ»¤å™¨
    try:
        filter = PhraseSimilarityFilter(model_name=args.model, device=args.device)
    except Exception as e:
        print(f"âŒ Failed to initialize CLIP model: {e}")
        return

    # æ‰§è¡Œè¿‡æ»¤
    try:
        results = filter.filter_all_categories(
            input_file=args.input,
            output_file=args.output,
            top_k=args.top_k
        )

        print("\nğŸ‰ Filtering completed successfully!")
        print(f"Results saved to: {args.output}")

    except Exception as e:
        print(f"âŒ Filtering failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()