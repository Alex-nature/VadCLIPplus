#!/usr/bin/env python3
"""
ä½¿ç”¨Cherry Studio APIä¸ºå¼‚å¸¸æ£€æµ‹ç±»åˆ«ç”ŸæˆLLMå¢å¼ºçš„çŸ­è¯­
"""

import requests
import json
import time
import os
from pathlib import Path
from typing import Dict, List

class CherryStudioPhraseGenerator:
    """
    ä½¿ç”¨Cherry Studio APIç”Ÿæˆå¼‚å¸¸æ£€æµ‹ç±»åˆ«çš„æè¿°çŸ­è¯­
    """

    def __init__(self, api_key: str, base_url: str = "https://chat.cloudapi.vip"):
        """
        åˆå§‹åŒ–Cherry Studioç”Ÿæˆå™¨

        Args:
            api_key: Cherry Studio APIå¯†é’¥
            base_url: Cherry StudioæœåŠ¡å™¨åœ°å€
        """
        self.api_key = api_key
        self.base_url = base_url.rstrip('/')
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

    def generate_phrase_for_category(self, category: str, num_phrases: int = 5) -> List[str]:
        """
        ä¸ºå•ä¸ªç±»åˆ«ç”Ÿæˆæè¿°çŸ­è¯­

        Args:
            category: å¼‚å¸¸ç±»åˆ«åç§°
            num_phrases: ç”ŸæˆçŸ­è¯­æ•°é‡

        Returns:
            çŸ­è¯­åˆ—è¡¨
        """
        prompt = f"""
        Generate {num_phrases} different descriptive phrases for the anomaly category "{category}" in video anomaly detection.

        Requirements:
        1. Each phrase should describe specific manifestations of this abnormal behavior
        2. Phrases should be concise and clear, between 3-8 words in length
        3. Avoid using the category name itself
        4. Cover different aspects of behavior (actions, context, consequences, etc.)
        5. Ensure diversity and accuracy of phrases

        Return exactly {num_phrases} phrases, one per line, without additional explanations.
        """

        payload = {
            "model": "gpt-5.2",  # æˆ–å…¶ä»–å¯ç”¨çš„æ¨¡å‹
            "messages": [
                {
                    "role": "system",
                    "content": "You are a professional expert in video anomaly detection, capable of accurately describing various abnormal behaviors."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 300,
            "temperature": 0.7,
            "stream": False
        }

        try:
            url = f"{self.base_url}/v1/chat/completions"
            response = requests.post(url, json=payload, headers=self.headers, timeout=60)
            response.raise_for_status()

            result = response.json()
            if "choices" in result and len(result["choices"]) > 0:
                response_text = result["choices"][0]["message"]["content"].strip()
                phrases = [line.strip() for line in response_text.split('\n') if line.strip()]
                return phrases[:num_phrases]  # ç¡®ä¿è¿”å›æ­£ç¡®æ•°é‡
            else:
                print(f"Warning: Unexpected API response for category '{category}'")
                return []

        except requests.exceptions.RequestException as e:
            print(f"API request failed for category '{category}': {e}")
            return []
        except Exception as e:
            print(f"Error processing category '{category}': {e}")
            return []

    def generate_all_categories(self, num_phrases: int = 5) -> Dict[str, List[str]]:
        """
        ä¸ºæ‰€æœ‰UCF-Crimeå¼‚å¸¸ç±»åˆ«ç”ŸæˆçŸ­è¯­

        Args:
            num_phrases: æ¯ä¸ªç±»åˆ«ç”Ÿæˆçš„çŸ­è¯­æ•°é‡

        Returns:
            ç±»åˆ«åˆ°çŸ­è¯­åˆ—è¡¨çš„å­—å…¸
        """
        # UCF-Crimeæ•°æ®é›†çš„å¼‚å¸¸ç±»åˆ«
        categories = [
            'abuse', 'arrest', 'arson', 'assault', 'burglary', 'explosion',
            'fighting', 'roadAccidents', 'robbery', 'shooting', 'shoplifting',
            'stealing', 'vandalism'
        ]

        results = {}

        print(f"Starting phrase generation for {len(categories)} categories...")
        print(f"Generating {num_phrases} phrases per category\n")

        for i, category in enumerate(categories, 1):
            print(f"[{i}/{len(categories)}] Generating phrases for '{category}'...")

            phrases = self.generate_phrase_for_category(category, num_phrases)

            if phrases:
                results[category] = phrases
                print(f"  âœ“ Generated {len(phrases)} phrases")
                for j, phrase in enumerate(phrases, 1):
                    print(f"    {j}. {phrase}")
            else:
                print(f"  âœ— Failed to generate phrases for '{category}'")
                results[category] = []  # ç©ºåˆ—è¡¨è¡¨ç¤ºå¤±è´¥

            # é¿å…APIé™åˆ¶
            if i < len(categories):  # æœ€åä¸€ä¸ªä¸éœ€è¦ç­‰å¾…
                time.sleep(1)

        return results

    def save_to_json(self, phrases_dict: Dict[str, List[str]], output_file: str = "enhanced_prompts.json"):
        """
        ä¿å­˜ç”Ÿæˆçš„çŸ­è¯­åˆ°JSONæ–‡ä»¶

        Args:
            phrases_dict: ç±»åˆ«åˆ°çŸ­è¯­çš„å­—å…¸
            output_file: è¾“å‡ºæ–‡ä»¶å
        """
        # æ„å»ºå®Œæ•´çš„JSONç»“æ„
        data = {
            "metadata": {
                "description": "Enhanced text prompts for video anomaly detection categories",
                "generator": "CherryStudioPhraseGenerator",
                "total_categories": len(phrases_dict),
                "total_phrases": sum(len(phrases) for phrases in phrases_dict.values()),
                "phrases_per_category": len(list(phrases_dict.values())[0]) if phrases_dict else 0,
                "api_provider": "Cherry Studio"
            },
            "categories": phrases_dict
        }

        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            print(f"\nâœ“ Phrases saved to {output_file}")
            print(f"  - Categories: {len(phrases_dict)}")
            print(f"  - Total phrases: {sum(len(phrases) for phrases in phrases_dict.values())}")

        except Exception as e:
            print(f"âœ— Failed to save file: {e}")

    def load_from_json(self, json_file: str) -> Dict[str, List[str]]:
        """
        ä»JSONæ–‡ä»¶åŠ è½½çŸ­è¯­

        Args:
            json_file: JSONæ–‡ä»¶å

        Returns:
            ç±»åˆ«åˆ°çŸ­è¯­çš„å­—å…¸
        """
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if "categories" in data:
                phrases_dict = data["categories"]
                print(f"âœ“ Loaded {len(phrases_dict)} categories from {json_file}")

                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                if "metadata" in data:
                    meta = data["metadata"]
                    print(f"  - Total phrases: {meta.get('total_phrases', 0)}")
                    print(f"  - Generator: {meta.get('generator', 'Unknown')}")

                return phrases_dict
            else:
                print(f"âœ— Invalid JSON format in {json_file}")
                return {}

        except Exception as e:
            print(f"âœ— Failed to load JSON file: {e}")
            return {}

    def get_failed_categories(self, json_file: str = "enhanced_prompts.json") -> List[str]:
        """
        è·å–ç”Ÿæˆå¤±è´¥çš„ç±»åˆ«ï¼ˆçŸ­è¯­åˆ—è¡¨ä¸ºç©ºçš„ç±»åˆ«ï¼‰

        Args:
            json_file: JSONæ–‡ä»¶è·¯å¾„

        Returns:
            å¤±è´¥ç±»åˆ«çš„åˆ—è¡¨
        """
        phrases_dict = self.load_from_json(json_file)
        failed_categories = [category for category, phrases in phrases_dict.items() if not phrases]
        return failed_categories

    def regenerate_failed_categories(self, json_file: str = "enhanced_prompts.json", num_phrases: int = 5) -> Dict[str, List[str]]:
        """
        é‡æ–°ç”Ÿæˆå¤±è´¥çš„ç±»åˆ«çŸ­è¯­

        Args:
            json_file: ç°æœ‰çš„JSONæ–‡ä»¶è·¯å¾„
            num_phrases: æ¯ä¸ªç±»åˆ«ç”Ÿæˆçš„çŸ­è¯­æ•°é‡

        Returns:
            æ›´æ–°åçš„çŸ­è¯­å­—å…¸
        """
        # è·å–å¤±è´¥çš„ç±»åˆ«
        failed_categories = self.get_failed_categories(json_file)

        if not failed_categories:
            print("âœ“ All categories have been successfully generated!")
            return self.load_from_json(json_file)

        print(f"Found {len(failed_categories)} failed categories: {failed_categories}")
        print(f"Regenerating {num_phrases} phrases for each failed category...\n")

        # åŠ è½½ç°æœ‰æ•°æ®
        phrases_dict = self.load_from_json(json_file)

        # é‡æ–°ç”Ÿæˆå¤±è´¥çš„ç±»åˆ«
        updated_count = 0
        for i, category in enumerate(failed_categories, 1):
            print(f"[{i}/{len(failed_categories)}] Regenerating phrases for '{category}'...")

            phrases = self.generate_phrase_for_category(category, num_phrases)

            if phrases:
                phrases_dict[category] = phrases
                updated_count += 1
                print(f"  âœ“ Successfully regenerated {len(phrases)} phrases")
                for j, phrase in enumerate(phrases, 1):
                    print(f"    {j}. {phrase}")
            else:
                print(f"  âœ— Failed to regenerate phrases for '{category}'")

            # é¿å…APIé™åˆ¶
            if i < len(failed_categories):
                time.sleep(1)

        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        if updated_count > 0:
            self.save_to_json(phrases_dict, json_file)
            print(f"\nâœ“ Updated {updated_count} categories in {json_file}")

        return phrases_dict


def main():
    """
    ä¸»å‡½æ•°
    """
    import argparse

    parser = argparse.ArgumentParser(description="Cherry Studio LLM Phrase Generator")
    parser.add_argument("--regenerate-failed", action="store_true",
                       help="Only regenerate phrases for failed categories")
    parser.add_argument("--num-phrases", type=int, default=20,
                       help="Number of phrases per category (default: 5)")
    parser.add_argument("--output", type=str, default="enhanced_prompts.json",
                       help="Output JSON file path")

    args = parser.parse_args()

    print("=== Cherry Studio LLM Phrase Generator ===\n")

    # è·å–APIå¯†é’¥
    api_key = os.getenv("CHERRY_STUDIO_API_KEY")
    if not api_key:
        # å°è¯•ä».envæ–‡ä»¶è¯»å–
        env_file = Path(".env")
        if env_file.exists():
            try:
                with open(env_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#') and 'CHERRY_STUDIO_API_KEY=' in line:
                            api_key = line.split('=', 1)[1].strip().strip('"').strip("'")
                            break
            except Exception as e:
                print(f"Error reading .env file: {e}")

    if not api_key:
        print("âŒ API key not found. Please set CHERRY_STUDIO_API_KEY environment variable")
        print("or add it to .env file:")
        print("CHERRY_STUDIO_API_KEY=your-api-key-here")
        return

    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = CherryStudioPhraseGenerator(api_key)

    if args.regenerate_failed:
        # åªé‡æ–°ç”Ÿæˆå¤±è´¥çš„ç±»åˆ«
        print("ğŸ”„ Regenerating failed categories...\n")
        phrases_dict = generator.regenerate_failed_categories(args.output, args.num_phrases)

        # æ˜¾ç¤ºç»“æœ
        failed_categories = generator.get_failed_categories(args.output)
        successful_categories = len(phrases_dict) - len(failed_categories)
        total_phrases = sum(len(phrases) for phrases in phrases_dict.values())

        print("\n=== Regeneration Summary ===")
        print(f"âœ“ Successfully processed {len(phrases_dict)} categories")
        print(f"âœ“ Remaining failed categories: {len(failed_categories)}")
        if failed_categories:
            print(f"  Failed: {failed_categories}")
        print(f"âœ“ Total phrases: {total_phrases}")

    else:
        # å®Œæ•´ç”Ÿæˆæ‰€æœ‰ç±»åˆ«çš„çŸ­è¯­
        phrases_dict = generator.generate_all_categories(num_phrases=args.num_phrases)

        if phrases_dict:
            # ä¿å­˜ç»“æœ
            generator.save_to_json(phrases_dict, args.output)

            # æ˜¾ç¤ºæ‘˜è¦
            print("\n=== Generation Summary ===")
            successful_categories = sum(1 for phrases in phrases_dict.values() if phrases)
            total_phrases = sum(len(phrases) for phrases in phrases_dict.values())

            print(f"âœ“ Successfully generated phrases for {successful_categories}/{len(phrases_dict)} categories")
            print(f"âœ“ Total phrases generated: {total_phrases}")
            print(f"âœ“ Results saved to {args.output}")
        else:
            print("âŒ No phrases were generated")


if __name__ == "__main__":
    main()